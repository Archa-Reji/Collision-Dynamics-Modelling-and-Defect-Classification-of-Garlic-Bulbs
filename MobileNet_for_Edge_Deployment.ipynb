{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vapIypJtjfk8",
        "outputId": "75966e7d-d321-443d-c5a3-835d10deb7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.108-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.108-py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.8/974.8 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.108 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsqxx875HKul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_FVvhgmkINQ",
        "outputId": "93f0ab78-e091-4583-9009-4e9e64afc60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyaml\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml) (6.0.2)\n",
            "Downloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml\n",
            "Successfully installed pyaml-25.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdEsSq7ikeMM",
        "outputId": "cc9fc1b7-7240-4d40-ccda-6ba3aa51c811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8bt9W83klIb",
        "outputId": "d8e9461f-7700-4ae0-c5a4-dfef46ec8213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Dataset paths\n",
        "data_paths = {\n",
        "    'background': \"/content/drive/MyDrive/garlic_yolo_sort/back_ground\",\n",
        "    'damaged': \"/content/drive/MyDrive/garlic_yolo_sort/damaged_garlic\",\n",
        "    'healthy': \"/content/drive/MyDrive/garlic_yolo_sort/healthy_garlic\"\n",
        "}\n",
        "\n",
        "# Collect all images with their labels\n",
        "def load_dataset():\n",
        "    data = []\n",
        "    class_ids = {'background': 0, 'damaged': 1, 'healthy': 2}\n",
        "\n",
        "    for class_name, path in data_paths.items():\n",
        "        class_id = class_ids[class_name]\n",
        "        for img_file in os.listdir(path):\n",
        "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                data.append((os.path.join(path, img_file), class_id))\n",
        "\n",
        "    random.shuffle(data)\n",
        "    return data\n",
        "\n",
        "# Load and split dataset\n",
        "full_dataset = load_dataset()\n",
        "train_data, test_data = train_test_split(full_dataset, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Total samples: {len(full_dataset)}\")\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "\n",
        "# Custom Dataset Class\n",
        "class GarlicDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = GarlicDataset(train_data)\n",
        "test_dataset = GarlicDataset(test_data)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFV8Cc3HpGnf",
        "outputId": "e52e215d-f2ea-4987-85b6-92e54c0d9350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 2364\n",
            "Training samples: 1654\n",
            "Test samples: 710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "76-pr7_rtf7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Dataset paths\n",
        "data_paths = {\n",
        "    'background': \"/content/drive/MyDrive/garlic_yolo_sort/back_ground\",\n",
        "    'damaged': \"/content/drive/MyDrive/garlic_yolo_sort/damaged_garlic\",\n",
        "    'healthy': \"/content/drive/MyDrive/garlic_yolo_sort/healthy_garlic\"\n",
        "}\n",
        "\n",
        "# Collect all images with their labels\n",
        "def load_dataset():\n",
        "    data = []\n",
        "    class_ids = {'background': 0, 'damaged': 1, 'healthy': 2}\n",
        "\n",
        "    for class_name, path in data_paths.items():\n",
        "        class_id = class_ids[class_name]\n",
        "        for img_file in os.listdir(path):\n",
        "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                data.append((os.path.join(path, img_file), class_id))\n",
        "\n",
        "    random.shuffle(data)\n",
        "    return data\n",
        "\n",
        "# Load and split dataset\n",
        "full_dataset = load_dataset()\n",
        "train_data, test_data = train_test_split(full_dataset, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Total samples: {len(full_dataset)}\")\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "\n",
        "# Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Custom Dataset Class\n",
        "class GarlicDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = GarlicDataset(train_data, transform=transform)\n",
        "test_dataset = GarlicDataset(test_data, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuJd-e4hxBOa",
        "outputId": "cded1bf4-6b25-42f7-9d99-6271452f23ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 2364\n",
            "Training samples: 1654\n",
            "Test samples: 710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a Keras-compatible model (MobileNetV2 for RPi)\n",
        "def create_keras_model(num_classes=3):\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(224, 224, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = True\n",
        "\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=True)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Convert PyTorch DataLoader to Keras-compatible format\n",
        "def dataloader_to_keras(dataloader):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for batch in dataloader:\n",
        "        batch_images, batch_labels = batch\n",
        "        batch_images = batch_images.numpy().transpose(0, 2, 3, 1)\n",
        "        batch_labels = batch_labels.numpy()\n",
        "\n",
        "        # Denormalize images\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        batch_images = std * batch_images + mean\n",
        "        batch_images = np.clip(batch_images, 0, 1)\n",
        "\n",
        "        images.append(batch_images)\n",
        "        labels.append(batch_labels)\n",
        "\n",
        "    return np.concatenate(images), np.concatenate(labels)\n",
        "\n",
        "# Prepare data for Keras\n",
        "x_train, y_train = dataloader_to_keras(train_loader)\n",
        "x_test, y_test = dataloader_to_keras(test_loader)\n",
        "\n",
        "# Create and train Keras model with callbacks\n",
        "keras_model = create_keras_model()\n",
        "\n",
        "# Callbacks to save best model and early stopping\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_garlic_classifier.h5',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LF4DaC8xRBi",
        "outputId": "f5d5a549-4d43-419d-c5b9-ec02767a7fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = keras_model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n",
        "\n",
        "# Load the best saved model\n",
        "best_model = load_model('best_garlic_classifier.h5')\n",
        "\n",
        "# Evaluate the best model\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\"\\nBest Model Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "# Save the final model (optional)\n",
        "keras_model.save('final_garlic_classifier.h5')\n",
        "\n",
        "# Convert best model to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open('best_garlic_classifier.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "print(\"Best TFLite model saved as 'best_garlic_classifier.tflite'\")\n",
        "\n",
        "# Prediction function\n",
        "def predict_image(model, image_path):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img = img.resize((224, 224))\n",
        "\n",
        "    # Preprocess image\n",
        "    img_array = np.array(img) / 255.0\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img_array = (img_array - mean) / std\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Predict\n",
        "    predictions = model.predict(img_array)\n",
        "    class_id = np.argmax(predictions[0])\n",
        "    confidence = np.max(predictions[0])\n",
        "\n",
        "    class_names = ['background', 'damaged', 'healthy']\n",
        "    return class_names[class_id], confidence\n",
        "\n",
        "# Test prediction\n",
        "sample_image = test_data[0][0]\n",
        "pred_class, pred_conf = predict_image(best_model, sample_image)\n",
        "print(f\"\\nSample test image: {sample_image}\")\n",
        "print(f\"Predicted: {pred_class} with confidence {pred_conf:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGlVQK343dYn",
        "outputId": "0c5cc20f-5bb4-484d-d7a5-eef2a47b0e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.8977 - loss: 0.3267\n",
            "Epoch 1: val_accuracy improved from -inf to 0.30704, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 10s/step - accuracy: 0.8986 - loss: 0.3250 - val_accuracy: 0.3070 - val_loss: 19.5507\n",
            "Epoch 2/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.9650 - loss: 0.0940\n",
            "Epoch 2: val_accuracy did not improve from 0.30704\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 10s/step - accuracy: 0.9653 - loss: 0.0933 - val_accuracy: 0.2901 - val_loss: 22.1074\n",
            "Epoch 3/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9948 - loss: 0.0227\n",
            "Epoch 3: val_accuracy did not improve from 0.30704\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 9s/step - accuracy: 0.9948 - loss: 0.0227 - val_accuracy: 0.2901 - val_loss: 22.3129\n",
            "Epoch 4/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9869 - loss: 0.0399\n",
            "Epoch 4: val_accuracy improved from 0.30704 to 0.33662, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 9s/step - accuracy: 0.9870 - loss: 0.0398 - val_accuracy: 0.3366 - val_loss: 21.8018\n",
            "Epoch 5/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9975 - loss: 0.0185\n",
            "Epoch 5: val_accuracy improved from 0.33662 to 0.39577, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 9s/step - accuracy: 0.9973 - loss: 0.0191 - val_accuracy: 0.3958 - val_loss: 21.7391\n",
            "Epoch 6/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.9578 - loss: 0.1481\n",
            "Epoch 6: val_accuracy did not improve from 0.39577\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 9s/step - accuracy: 0.9582 - loss: 0.1469 - val_accuracy: 0.2901 - val_loss: 19.1269\n",
            "Epoch 7/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9827 - loss: 0.0622\n",
            "Epoch 7: val_accuracy did not improve from 0.39577\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 9s/step - accuracy: 0.9828 - loss: 0.0619 - val_accuracy: 0.3127 - val_loss: 11.6426\n",
            "Epoch 8/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9966 - loss: 0.0100\n",
            "Epoch 8: val_accuracy improved from 0.39577 to 0.48873, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 9s/step - accuracy: 0.9966 - loss: 0.0101 - val_accuracy: 0.4887 - val_loss: 18.7775\n",
            "Epoch 9/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9970 - loss: 0.0105\n",
            "Epoch 9: val_accuracy improved from 0.48873 to 0.58169, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 9s/step - accuracy: 0.9970 - loss: 0.0104 - val_accuracy: 0.5817 - val_loss: 13.7320\n",
            "Epoch 10/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9969 - loss: 0.0056\n",
            "Epoch 10: val_accuracy did not improve from 0.58169\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 9s/step - accuracy: 0.9969 - loss: 0.0056 - val_accuracy: 0.5296 - val_loss: 18.1255\n",
            "Epoch 11/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.9896 - loss: 0.0222\n",
            "Epoch 11: val_accuracy did not improve from 0.58169\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 9s/step - accuracy: 0.9896 - loss: 0.0224 - val_accuracy: 0.3803 - val_loss: 13.1425\n",
            "Epoch 12/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9849 - loss: 0.0444\n",
            "Epoch 12: val_accuracy improved from 0.58169 to 0.63239, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 9s/step - accuracy: 0.9850 - loss: 0.0441 - val_accuracy: 0.6324 - val_loss: 12.9899\n",
            "Epoch 13/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Epoch 13: val_accuracy did not improve from 0.63239\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.6324 - val_loss: 15.9797\n",
            "Epoch 14/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 1.0000 - loss: 1.1165e-04\n",
            "Epoch 14: val_accuracy improved from 0.63239 to 0.64225, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 1.1107e-04 - val_accuracy: 0.6423 - val_loss: 14.5283\n",
            "Epoch 15/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 1.0000 - loss: 6.3086e-05\n",
            "Epoch 15: val_accuracy improved from 0.64225 to 0.65775, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 6.2935e-05 - val_accuracy: 0.6577 - val_loss: 13.1233\n",
            "Epoch 16/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 1.0000 - loss: 4.9387e-05\n",
            "Epoch 16: val_accuracy improved from 0.65775 to 0.66338, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 4.9295e-05 - val_accuracy: 0.6634 - val_loss: 11.6912\n",
            "Epoch 17/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 1.0000 - loss: 4.0845e-05\n",
            "Epoch 17: val_accuracy improved from 0.66338 to 0.67606, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 4.0782e-05 - val_accuracy: 0.6761 - val_loss: 10.2507\n",
            "Epoch 18/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 1.0000 - loss: 3.4821e-05\n",
            "Epoch 18: val_accuracy improved from 0.67606 to 0.69718, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 3.4774e-05 - val_accuracy: 0.6972 - val_loss: 8.8536\n",
            "Epoch 19/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 3.0313e-05\n",
            "Epoch 19: val_accuracy improved from 0.69718 to 0.71690, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 10s/step - accuracy: 1.0000 - loss: 3.0278e-05 - val_accuracy: 0.7169 - val_loss: 7.5414\n",
            "Epoch 20/20\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 1.0000 - loss: 2.6785e-05\n",
            "Epoch 20: val_accuracy improved from 0.71690 to 0.73239, saving model to best_garlic_classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 2.6757e-05 - val_accuracy: 0.7324 - val_loss: 6.3145\n",
            "Restoring model weights from the end of the best epoch: 20.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.7583 - loss: 5.6564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model Test Accuracy: 73.24%\n",
            "Saved artifact at '/tmp/tmpa70_hynk'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer_1')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136548756602512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548755458192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548755459152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548755458000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548755458960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548755459920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548755457808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548622874960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548755457040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548755458384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548622873424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548622875920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548622874192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548622876304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548622874576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548622875344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598957456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598958416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548622875536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598957072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598959760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598960912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598961104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598960720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598957840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598961680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598962064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598962448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598962256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598958992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598963600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598963984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598964368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598964176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598956112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598965520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598965904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598966288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598966096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598959952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598967440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598967824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598968208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598968016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598963216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598969360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598969744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598970128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598969936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598965136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598971280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598970896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598968976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598971856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598967056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548598970512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667770064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667768912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667770256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667769104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667771600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667771984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667772368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667772176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667770448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667773520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667773904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667774288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667774096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667769680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667775440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667775824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667776208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667776016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667771216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667777360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667777744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667778128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667777936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667773136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667779280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667779664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667780048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667779856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667775056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667781200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667781584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667781968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667781776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667776976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667783120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667783504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667783888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667783696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667778896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667785040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667780816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667983056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667784656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667782736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667983632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667984016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667984400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667984208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667982864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667985552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667985936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667986320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667986128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667982096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667987472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667987856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667988240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667988048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667982288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667989392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667989776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667990160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667989968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667985168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667991312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667991696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667992080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667991888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667987088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667993232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667993616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667994000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667993808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667989008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667995152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667995536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667995920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667995728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667990928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667997072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667996688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667994768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667997648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667992848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548667996304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668146896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668146320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668147088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668146128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668148432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668148816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668149200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668149008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668147280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668150352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668150736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668151120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668150928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668145744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668152272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668152656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668153040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668152848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668148048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668154192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668154576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668154960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668154768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668149968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668156112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668156496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668156880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668156688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668151888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668158032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668158416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668158800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668158608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668153808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668159952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668160336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668160720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668160528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668155728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668161872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668157648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668293776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668161488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668159568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668294928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668295312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668295696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668295504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668294160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668296848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668297232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668297616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668297424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668293392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668298768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668299152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668299536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668299344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668294544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668300688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668301072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668301456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668301264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668296464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668302608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668302992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668303376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668303184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668298384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668304528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668304912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668305296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668305104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668300304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668306448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668306832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668307216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668307024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668302224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668308368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668307984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668306064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668308944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668304144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548668307600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666410192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666409616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666410384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666409424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666411728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666412112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666412496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666412304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666410576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666413648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666414032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666414416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666414224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666409232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666415568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666415952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666416336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666416144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666411344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666417488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666417872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666418256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666418064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666413264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666419408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666419792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666420176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666419984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666415184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666421328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666421712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666422096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666421904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666417104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666423248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136548666423824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Best TFLite model saved as 'best_garlic_classifier.tflite'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\n",
            "Sample test image: /content/drive/MyDrive/garlic_yolo_sort/damaged_garlic/image_79_aug_5.png\n",
            "Predicted: damaged with confidence 1.00\n"
          ]
        }
      ]
    }
  ]
}